% !TEX root = NSF_SuperCDMS_SNOLAB_OPS.tex
%% people who build community and knowledge
%% around software?
%% The maintainers
%% Educopia
%% http://ivory.idyll.org/blog/2019-communities-of-effort.html#disqus_thread
%% https://blog.dnanexus.com/2018-01-29-analysis-commons-a-collaborative-approach-to-multi-omics-discovery/

%% describing data
%https://library.si.edu/research/describing-your-data-data-dictionaries
%https://figshare.com/articles/The_State_of_Open_Data_Report_2017/5481187/1
%https://www.usgs.gov/products/data-and-tools/data-management/data-standards
%https://www.fgdc.gov/standards/standards_publications/
%http://www.ddialliance.org/ metadata standards for social sciences
%https://www.rd-alliance.org/groups/data-type-registries-wg.html research data alliance, not focused on physics AFAIK but definitely useful
%https://access-data.trydiscourse.com/
% XDR, external data format!!
% https://tools.ietf.org/html/rfc1832.html#section-6
% and there is a python library for it, xdrlib

% Mom says all the cool kids are using smartsheets
% Liquid Planner has a free plan for teachers?  https://app.liquidplanner.com/space/202855/projects

% documentation is often overlooked but people need it the most
% https://opensourcesurvey.org/2017/

\section{Solicitation-specific review criteria}
\subsection{Science-driven}
% How will the project outcomes fill well-recognized science and engineering needs of the research community, and advance research capability within a significant area or areas of science and engineering? What are the broader impacts of the project, such as benefits to science and engineering communities beyond initial targets, underrepresented communities, and education and workforce development? The project outcomes should address well-recognized science outcomes.

This project serves the immediate needs of researchers in the dark matter community and the experimental nuclear physics community by providing a common toolset for analyzing data in any format.  The PI expects that

\begin{itemize}
    \item Multiple research projects across the NSF directorate will be more productive because they can use existing, documented tools rather than building their own.  The PI intends to estimate this impact with citations from scientific papers.
    \item Increased involvement of undergraduate researchers in science analysis due to improved documentation and an extended support network.  The PI intends to measure this through undergraduate involvement in her own lab, community surveys, and tracking community forum data.
    \item Several example analyses will be publicly released, with accompanying documentation and support information for pre-requisite computing skills.  %The intent is for these educational materials to be accessible to someone with no domain knowledge.  The PI believes these training materials will be an equitable training resource.
\end{itemize}


\subsection{Innovation}
% What innovative and transformational capabilities will the project bring to its target communities, and how will the project integrate innovation and discovery into the project activities, such as through empirical research embedded as an integral component of the project activities? Such research might encompass reproducibility, provenance, effectiveness, usability, and adoption of the components, adaptability to new technologies and to changing requirements, and the development of lifecycle processes used in the project.

%A common limitation of data-analysis software that is entirely home-grown is that it does not scale as data grows and changes - a human has to update or rewrite the code if the requirements change substantially.

This library makes heavy use of existing libraries - this makes initial development easier and has the benefit  that as those libraries improve and scale to larger data sets, this software inherits that improvement.  

By leveraging well-supported, open-source libraries, the burden of supporting new systems is not an individual problem but instead is a problem for an active community that may be highly-motivated to find a solution.  %This library serves as sugar to allow scientists with many different data formats to take advantage of these popular libraries.

The danger to this approach is the same - if these libraries lose community support or focus on very different problems then this library will lose relevance over time.  To mitigate this risk, the PI is focusing on integrating with well-supported, modularly-designed libraries.

\subsection{Close collaboration among stakeholders}
% How will the project activities engage CI experts, specialists, and scientists and engineers working in concert with the relevant domain scientists and engineers who are users of CI?

The PI proposes to engage both cyberinfrastructure experts and the experimental nuclear physics community by (1) working closely with pilot experiments to build software that works effectively for scientists analyzing event-based data, (2) holding yearly workshops intended to foster interaction between the scientists using the software and cyberinfrastructure developers, and (3) attending conferences that will allow outreach to the scientific community (for example, the Low Energy Community Meeting) and the cyberinfrastructure community (for example, CHEP).

The PI has working relationships with scientists in the SuperCDMS collaboration and the XIA corporation, both of which are interested in exploring the proposed software as solutions to analysis needs.

In addition, the IRIS-HEP collaboration is interested in this work as it would extend their awkward-array library to a broader audience.  Awkward array was developed as part of DIANA/HEP \cite{diana-hep} and that effort will continue with IRIS-HEP \cite{iris-hep}
.  Collaborating with IRIS-HEP allows us to build on libraries created by experienced cyberinfrastructure developers who have focused on developing software suitable for terabyte-scale data.


\subsection{Building on existing, recognized capabilities}
% How will the project activities build on and leverage existing NSF and national cyberinfrastructure investments, as appropriate?

The proposed work builds on existing capabilities and communities in several ways:

\begin{itemize}
    \item \textbf{The PI proposes to use already-existing data description languages.}  The languages Katai Struct and the Data Format Description Langauage both have active communities and tools that work with data when provided a description.  Kaitai Struct is the target for the proposed work because (1) it is more human-readable than than the XML-based DFDL, and (2) Katai Struct generates code libraries that allow users to load their data into the programming environment of their choice; DFDL currently works by providing an XML or JSON equivalent of the binary data.  While this is a powerful approach because any language with an XML or JSON parser can now read the data, it also produces a secondary data file that is an order of magnitude larger than most binary files.  This makes DFDL, in its current state, unusable for scientists with gigabyte-scale data sets as it would make the required storage space for analysis prohibitively expensive.
    \item \textbf{The PI proposes to use already-existing infrastructure for the data-analysis library.}  Scientists who would like to avoid writing custom software to read their binary data can already use the Kaitai Struct compiler to generate libraries to read their data in python, C++, and a multitude of other languages.  The advantage is that there is substantial support documentation and an active community available for troubleshooting.  The disadvantage is that the current Kaitai Struct python compiler stores the data in a structure that does not provide adequate speed performance for gigabyte-scale data sets.  By improving the existing Katai Struct compiler software, we can build a science-ready analysis library and scientists can benefit from the existing community support and documentation.   
    \item \textbf{Use a supported and optimized data structure}  for the improvements to the Kaitai Struct compiler.  The ``awkward-array'' library was developed by DIANA/HEP and is now supported by IRIS-HEP and is part of a set of libraries designed to provide flexible data-analysis tools for the high-energy physics community.  The awkward-array data structure is optimized for fast queries on an event-based data set and as such is ideal for the majority of nuclear physics data.  By choosing this data structure as the target, we bring the optimized and convenient analysis environment of awkward-array to any scientist who describes their data with the Katai Struct language.
    \item \textbf{Provide analysis tools for the python environment and training materials that take advantage of the python ecosystem.}  Python has enjoyed significant adoption in the scientific community; enough so that python support is compiled into the dominant high-energy physics software, ROOT, by default.  By providing a python library for data analysis, scientists can make use of a full ecosystem that supports data analysis: numpy for convenient array manipulation \cite{numpy}; scipy for fitting \cite{scipy}; matplotlib for producing publication-quality figures \cite{matplotlib}; and even numba for easy compilation of code that needs to run fast \cite{numba}.  Users can install the Anaconda Python distribution on any system, without elevated privelages.  The python community has invested significant effort into lowering the barrier to use and this project inherits this ecosystem.  %There are many , notably the Jupyter environment.  Code written in this environment is particularly nice as a tutorial because it is rendered nicely on github, gitlab, and interactive notebooks can be opened in one click through the binder webservice \cite{binder}.  
    
\end{itemize}

\subsection{Project plans, and system and process architecture}
% For an "Elements" proposal, the Project Description should include a high-quality management plan. The proposal should include user interactions and a community-driven approach, and provide a timeline including a proof-of-concept demonstration of the key components. Software or data cyberinfrastructure services should be sufficiently described and follow industry best practices, including the architecture of the CI and the engineering process to be used for the design, development, documentation, testing, validation, and release of the software, its deployment and associated outreach to the end user community, and an acceptance and evaluation plan that involves end users. The description of the CI architecture and processes should explain how security, trustworthiness, provenance, reproducibility, and usability will be addressed by the project and integrated into the proposed system and the engineering process, and how adaptability to new technologies and changing requirements will be addressed by the project and built into the proposed system, as appropriate.


\textbf{Architecture of the software:}
The architecture of the Kaitai Struct compiler that targets an awkward-array data structure will follow that of the existing Katai Struct software.  Implementing a Kaitai Struct compiler for a new language requires

\begin{enumerate}
    \item Writing a ``runtime library'' that provides a standard stream interface in the target language.  For example, one of the functions every language needs to have defined is a method that returns the size of the file or string stream.  By writing a ``size'' function for the language of interest that follows the Katai Struct API, the code generation becomes simpler.
    \item Writing a ``compiler'' that translates Kaitai Struct concepts, implemented in Scala, into the target language.
    \item Writing a test runner for the new language. 
\end{enumerate}

The proposed work targets the python environment, and there is already a Kaitai Struct python compiler.  The ``compiler'' for the python implementation, however, stores data in native-python data structures that provide inconveniently slow access to standard queries on large, gigabyte-scale data sets.  

The changes that need to be implemented to instead store the data in the faster awkward-array data will require modifying the existing compiler code and modifying the existing test code.  The existing code, although slow for science use, provides an excellent template for the proposed work.

\begin{comment}
\begin{lstlisting}
def [*size(self)*]:
    # Python has no internal File object API function to get
    # current file / StringIO size, thus we use the following
    # trick.
    io = self._io
    # Remember our current position
    [*cur_pos = *]io.tell()
    # Seek to the end of the File object
    io.seek(0, SEEK_END)
    # Remember position, which is equal to the full length
    [*full_size = *]io.tell()
    # Seek back to the current position
    [*io.seek(cur_pos)*]
[*return full_size*]
\end{lstlisting}

\begin{lstlisting}
uint64_t kaitai::kstream::[*size()*] {
    std::iostream::pos_type [*cur_pos = *]m_io->tellg();
    m_io->seekg(0, std::ios::end);
    std::iostream::pos_type [*len = *]m_io->tellg();
    [*m_io->seekg(cur_pos)*];
    [*return len*];
}
\caption{The details of this code are not important.  What is significant is the name of this function, size(), and its behavior: find and report the size of the file, without changing where we are in the file.  The Katai Struct compiler for both C++ and python can use the ``size()'' function rather than including these language-specific stream commands, making the compiler code more readable.}
\end{lstlisting}
\end{comment}

\textbf{Architecture of the user documentation:} User documentation should make it possible for users with little to no domain knowledge to use the data-access library for science.  Documentation for the use of the library will be stored as text files in the repository with the code.  A documentation generator, Antora [cite], will be used to generate searchable documentation with minimal effort.  The following documentation will be provided:

\begin{enumerate}
    \item How to get help with questions or issues about the library.
    \item How to install the library and its dependencies.
    \item An overview explaining what the user will need to provide (data and a description of the data) and what the library will provide (software to read that data).
    \item A tutorial walking through the use-case of a scientist looking at simple data with a custom format.
    \item Links to additional resources detailing more complex data formats and more complex analyses.
    \item Citation guidelines.  
\end{enumerate}


\textbf{Architecture of the developer documentation.}  Documentation intended to facilitate development of the code will also be stored as text files alongside alongside the code.  Every repository will document:

\begin{enumerate}
    \item How to install, develop, and test the code for individuals who wish to make changes.  
    \item How to contribute changes back to the project.  This will provide instructions on the version control practices used by the repository maintainers and instructions for implementing the tests required for changes to be considered for merging with the main code base.
\end{enumerate}

\textbf{Architecture of the basic scientific computing skills documentation:}  Documentation of basic computational skills and concepts will have several possible forms: (1) text and images, (2) tutorial videos, (3) jupyter notebooks, (4) posters that illustrate a focused concept, and (5) links to recommended resources such as Software Carpentry \cite{software-carpentry} tutorials.

All materials will be licensed with  a permissive, open-source license such as CC-BY or MIT.  The source for all the materials will be publicly available through a public host such as github or gitlab and will be archived on a content-tracker such as the Open Science Framework or Figshare.

All materials will be disseminated using a static site generated by Antora \cite{antora}.  Antora is specifically designed for documentation and allows a user to specify a set of repositories containing text files formatted in the Asciidoc markdown language to build a single, searchable documentation site.  Because Antora generates a static site, free hosting services are readily available.  This solution allows my students to focus on creating material to explain core concepts and practice interacting with version control rather than spending time wrestling with web development.

%The topics students choose to document are largely student-led, with some guidance from the PI.  Spring 2019 marks the inception of this project, and the concepts chosen by students for illustration have focused on (1) tutorial-format guide for installing python and running a basic python-based analysis of gamma spectroscopy data, (2) instructions for using a docker container to simplify installation of a complex software environment, and (3) a poster explaining what an executable file is.

Like all the other software products, the basic-skills materials  will include documentation that directs users to the forum for questions or issues and  that details how users can contribute. 


\textbf{Engineering processes:}
% design, development, documentation, testing, validation, and release of the software
% and
% description of the CI architecture and processes should explain how security, trustworthiness, provenance, reproducibility, and usability will be addressed by the project and integrated into the proposed system and the engineering process
A primary goal of the proposed work is to build software that can be supported and maintained by the community.  A primary risk of the proposed work is staff turnover and associated loss of knowledge and onboarding time.

The software design, development, documentation, and testing work together to make it easy for the community to contribute to the software development - a goal that mitigates turnover risk as well.

The design process of the software will start with project documentation that describes (1) use cases, (2) requirements, (3) assumptions, (4) key decisions, and (5) definitions.  Such documentation is particularly useful for programmers who lack experience in experimental nuclear physics data analysis and makes it easier for skilled experts to contribute to the project.  This documentation also serves as a way to focus community discussions into defining a minimum useful scope for the software.

The development of all software in the PI's lab is done using version control software (git) and a central ``repository server'' that everyone interacts with.  Cloud-based servers such as github and gitlab are used because they are easy to use, provide robust backups, and also serve as a platform for dissemination and collaboration.

The PI prioritizes (1) easy-to-get, working code and (2) rapid updates.  This is implemented by building end-to-end tests and configuring automatic test running triggered by any changes to the repository.  Because automated tests will be developed at the beginning of the project, developers can be encouraged to put their changes on the public, master branch.  Semantic versioning will be used to alert users to breaking changes.

%Work that breaks tests MUST be maintained on a separate ``branch'' that is publicly available but that will only be available to users by explicit action.  Instructions for developing code on such a branch will be included in the contributions documentation.

Simple end-to-end tests,  an automated testing framework, and high-quality documentation are key to stable development within the PI's lab and to encouraging community contributions.  This development strategy works well for the proposed project because the software goal is already well-defined and the initial plan for implementation - leverage the existing Kaitai Struct framework as much as possible - is clear.  In addition, this development strategy is well-supported by community solutions and the organization of the PI's lab:

\begin{itemize}
    \item end-to-end testing of python code - and even tutorial notebooks in jupyterlab format - enjoy a thriving ecosystem in Python.
    \item many automated testing frameworks are designed specifically to support developers using cloud-based repository hosts such as github and gitlab; many are freely available to open-source projects.
    \item novices are always on hand to test documentation.  The PI maintains a group of approximately six students, many of whom have minimal experience with scientific computing.
\end{itemize}

%In summary, the proposed code development will be strongly tied to documentation, automated testing, and documentation testing.

%\subsubsection{Security}

\subsubsection*{Trustworthiness}
End-to-end tests will be released with all the software released as part of the proposed work.

\subsubsection*{Provenance}
All releases will be archived with their own DOIs on Zenodo.  Guidance to cite the version of the software used will be included in the top-level README of all releases and posted on all related websites.

\subsubsection*{Reproducibility}
End-to-end tests of the software will completely define all inputs, including a reference data set, and compare the output to reference products such as histograms.  While this is not a complete test of reproducibility, it is a useful starting point and will serve end users and developers well.  

Instructions for system setup will be included in the documentation.  Full or partial system specifications using Docker are required for automatic test running and will be versioned together with the rest of the code.  More complete system specifications as provided by Nix and Guix will be considered if need arises for more complete reproducibility.

\subsubsection*{Usability}
The proposed software must be usable for (1) end users and (2) developers.  The requirements and planned implementation for each is given below:

\begin{tabularx}{\textwidth}{XX}
    \toprule
\multicolumn{2}{l}{\textbf{Can a scientist use this code to do data analysis on a custom-format data set?}}\\
    \toprule
    \textsc{requirements} & \textsc{implementation} \\
    \midrule

    $\sqcdot$ Is the scientist aware that this software exists?  Can the scientist find the software easily even if all they recall is a vague description?
    & Publications citing DOIs hosted on Zenodo with published preprints; well-indexed project website; open development on github, gitlab; indexed on python library repositories where appropriate \\
    \addlinespace[1mm]
    $\sqcdot$ Can the scientist install the software on their analysis computer easily, with or without root access?
    & Installation documentation; testing of installation documentation by novices; review of systems that need installation support at workshops \\
    \addlinespace[1mm]
    $\sqcdot$ Does the software apply itself well to this particular analysis need?  Can the scientist see how to use the software in their analysis?
    & Example analyses; testing of example analyses by novices; creation of a ``now you try'' document to test effectiveness. \\
    \addlinespace[1mm]
    $\sqcdot$ Does the scientist know where to get help or discuss issues with the software?
    & All documentation and code will contain a header directing users to the project forum and repository issue tracking. \\
    \addlinespace[1mm]
    \toprule
    \multicolumn{2}{l}{\textbf{Can an interested individual contribute to the development of the software?}}\\
    \toprule
    \textsc{requirements} & \textsc{implementation} \\
    \midrule
    $\sqcdot$ Is there a clear description of the requirements and purpose of the software so that developers can decide if they'd like to participate?
    & Requirements documentation and a description of use cases will precede all programming work and will be versioned with the rest of the code.\\
    \addlinespace[1mm]
    $\sqcdot$ Is it clear where to get help or discuss the code?
    & All documentation will link to the forum and the repository issue tracker.  The forum will be configured for web crawlers to maximize its discoverability.\\
    \addlinespace[1mm]
    $\sqcdot$ Are there clear and complete instructions on testing the software locally?
    & Local and remote testing infrastructure and documentation will be written as part of the first efforts.  Students will test these local development instructions.  Students will update the basic computing skills documentation as needed.\\
    \addlinespace[1mm]
    $\sqcdot$ Are there clear and complete contribution instructions?
    & Contribution instructions will be developed as part of the initial effort.  Students will test these contribution instructions.  Students will update the basic computing skills documentation as needed.\\
    \bottomrule
\end{tabularx}


\subsubsection*{Adaptability}
The proposed software intends to support scientific analysis of gigabyte-scale data for the coming decade.

Because the proposed software leverages existing, well-supported projects, any adaptations to changing data needs and opportunities made by the underlying libraries can potentially transfer to the proposed software with minimal effort.

There is always the possibility that these dependencies could be abandoned.  Archives of all dependent software will be made as a safeguard against this.  Other risk mitigation the PI will pursue is significant investment in automated testing and documentation, particularly interface documentation.

\subsection{Deployment and user outreach}
A key component of the user outreach will consist of annual workshops designed to promote hands-on use of the software and close collaboration with the software developers.  To maximize the effectiveness of these workshops,

\begin{itemize}
    \item Participants will be contacted in advance to begin early coordination of the analysis they're interested in doing with the data-access library
    \item Communication before and after the workshop will be encouraged through the maintenance of an open forum
    \item Prototype software will be released along with installation documentation, an example analysis, and contribution documentation prior to the workshop and tested by novices
    \item Discussion of the community roadmap will be integrated into the workshop and a new release of the roadmap will follow each workshop
    \item The conference will be registered on the Open Science Framework, providing an archived record of material prepared by participants.
\end{itemize}

Deployment of this software will use common open-source channels such as github, gitlab, and python package indexes such as PyPI and Conda.  Github and Gitlab both provide static page serving for projects.

Project communication will use the built-in issue tracking provided by repository hosts and open forum software such as Discourse.  Live-chat is not an anticipated need, but if it becomes clear this would be useful then the PI will consider using freely-available chat services such as Slack, Zulip, or Gitter.

Deployment of the software will also happen through academic channels such as preprint servers, project releases on the Open Science Framework, and/or Figshare.



\subsection{Acceptance and evaluation}

Community adoption of this software is central to the success and broader impact of this project.

The simplest metrics of community use will be (1) citations of software in peer-reviewed scientific papers and (2) the number of contributions to the code from developers outside the PI's group.

The primary evaluation the PI intends to use are interviews to understand how the software meets (or not) the needs of individual scientists.  This feedback will directly inform decisions about priorities and have an official outlet in the release of an annual roadmap.  


\subsection{Deliverables}
% Does the proposed project clearly articulate the services and capabilities to be delivered, and how they are to be delivered? NSF encourages exploration of various delivery mechanisms, including but not limited to, those leveraging eXtreme Science and Engineering Discovery Environment (XSEDE), leadership-class computing resources, OAC Software Institutes, Big Data Regional Innovation Hubs, individual organizational resources, and well-known public and private cloud services.
The deliverables of the proposed work are (1) a data-access library that works well for gigabyte-scale data of any format, (2) documentation that allows novices to use the sofware and scientist-developers to contribute to the software, and (3) annual workshops that bring the science and developer communities together.

The software and related documentation will all be developed openly on gitlab.  All documentation will be repeatedly tested by undergraduate students in the PI's lab.

Software releases will be granted a DOI through Zenodo; all publications will be released on preprint servers.  Additional deployment methods will be considered, such as packaging the software for commonly-used python installers like pip and conda.  Depending on community needs, general-purpose installers like Spack \cite{spack} and container environments like Docker \cite{ssi-docker, docker} or Nix \cite{nix-hpc, nix} may be published with the software.  In addition, the PI will work with the Science Gateways Community Institute to identify additional ways to deliver these products effectively to the community.

The yearly workshops will use the Open Science Framework's ``Meetings'' feature to ensure accessibility of materials prepared for the conference.  In addition, the PI will maintain a public, online forum for community discussion, pre-workshop planning, and roadmap planning.


\subsection{Metrics}
% Does the proposed project clearly articulate quantifiable metrics for development and delivery of the services and capabilities to be delivered by the project, and for the anticipated community adoption and usage? Are quantitative metrics with targets identified for each year of the award? These should be simple but should also clearly show what the project will accomplish each year, the impact on science, and the breadth of the user community.
The simplest evaluation metrics of community adoption and use will be (1) citations of software in peer-reviewed scientific papers and (2) the number of contributions to the code from developers outside the PI's group.

\textbf{In Year 1}  the PI expects to meet the following metrics of community involvement:
%\subsubsection*{Year 1}
\begin{itemize}
  \item Between 15 and 20 scientists register for the Data Access workshop.  These scientists are expected to predominantly come from the nuclear physics community.  The PI expects all attendees to register after specific invitation.
  \item Between 5 and 10 scientists register projects with the Open Science Framework or similar platform to work on analysis of their data collaboratively
  \item An initial release of the improved software and the XIA library is made.  Both have basic testing coverage, are tested automatically upon commit, and have initial guidelines for contribution.
  \item An initial release of the skills documentation has been made.  Inexperienced students who try to follow the analysis tutorial are able to find answers to some of their questions but most are expected to be unable to complete the tutorial without expert assistance
  \item A roadmap for the data-access  library is published post the workshop
\end{itemize}

\textbf{In Year 2}
the PI expects to meet similar goals, but with more community support.  The PI expects one or two attendees to find out and register for the conference from someone outside the group and for most to register after specific invitation.  The PI expects more researchers to pre-register their analysis on the Open Science Framework.  It is expected that the releases of the software and documentation will improve the community-identified pain points significantly, and that there will be continued involvement in roadmap discussions during the workshop.

%\subsubsection*{Year 3}
\textbf{In Year 3}
the PI expects to see broader community support.  Most notably, it is expected that the data-access software will be cited in 2 to 5 peer-reviewed papers that present scientific results.

The PI expects that issues with the software and documentation will be relatively minor and that the ecosystem, now well-developed, will promote approximately half the scientists to pre-register their analysis before the workshop.  The PI expects that the roadmap discussion will involve multiple viable plans for the sustainability and continued maintenance of the software. 

\subsection{Sustained and sustainable impacts}
%The Project Description should address how the project outcomes and its activities will have long-term impacts, and how these will be sustained beyond the lifetime of the award, as appropriate. Manuals and tutorials for using the developed CI should be delivered to the community. Software or data cyberinfrastructure services must identify the intended license to be used for the released CI, and the justification for the choice of this license. PIs who have been previously funded under previous CI awards should show quantifiable evidence of the use, impact and sustainability of the previously funded work (and include a citation to the published CI in their biographical sketches as one of their relevant products, if appropriate).

The goal of the proposed work is to significantly increase the accessibility of scientific data analysis on custom-format binary data.

The proposed work will not eliminate the need for developing custom software within institutions and groups - but the project will provide a common toolset that will work for the majority of gigabyte-scale, event-based analysis despite the lack of a uniform data format.  The success of this project is expected to

\begin{itemize}
    \item Reduce redundant time spent on writing and wrangling custom data-access software
    \item Significantly increase the involvement of students in the science-analysis phase of research
    \item Improve the reproducibility of science results 
\end{itemize}

The success of this project depends on significant community involvement; the PI believes that the flexible nature of the proposed software, its immediate need for many in the community, and the community-building work of the grant can achieve these goals.

The plan for long-term sustainability of this project is twofold.  (1) By keeping the scope of the proposed software small, the PI expects this software to be in a mature, usable state by the end of these funds.   (2) It is expected that the work proposed will build a community of users and developers who will continue to support the software because it is directly useful to their science goals.

To ensure community development during the course of this funding, the PI will work with the Science Gateways Community Institute to identify ways to strengthen community involvement.